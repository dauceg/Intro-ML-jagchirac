{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- READING IN THE PROVIDED DATA\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd \n",
    "\n",
    "from   sklearn import linear_model\n",
    "from   sklearn.metrics import mean_squared_error, r2_score\n",
    "from   sklearn.model_selection import KFold\n",
    "from   sklearn.model_selection import cross_val_score\n",
    "from   sklearn.linear_model import Ridge, Lasso, LassoLarsCV\n",
    "\n",
    "N_TData = 900;   # data set contains 900 elements\n",
    "\n",
    "# Train data\n",
    "ID  = np.zeros(N_TData)\n",
    "y   = np.zeros(N_TData)\n",
    "x1  = np.zeros(N_TData)\n",
    "x2  = np.zeros(N_TData)\n",
    "x3  = np.zeros(N_TData)\n",
    "x4  = np.zeros(N_TData)\n",
    "x5  = np.zeros(N_TData)\n",
    "\n",
    "# Reading the training data\n",
    "with open('train1B.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter = ',')\n",
    "    for row in reader:\n",
    "        ID[int(row['Id'])] = row['Id']\n",
    "        y[int(row['Id'])]  = np.float64(row['y'])\n",
    "        x1[int(row['Id'])] = np.float64(row['x1'])\n",
    "        x2[int(row['Id'])] = np.float64(row['x2'])\n",
    "        x3[int(row['Id'])] = np.float64(row['x3'])\n",
    "        x4[int(row['Id'])] = np.float64(row['x4'])\n",
    "        x5[int(row['Id'])] = np.float64(row['x5'])\n",
    "\n",
    "# Transform the data accordingly\n",
    "\n",
    "# Linear\n",
    "phy_1  = x1\n",
    "phy_2  = x2\n",
    "phy_3  = x3\n",
    "phy_4  = x4\n",
    "phy_5  = x5\n",
    "\n",
    "# Quadratic\n",
    "phy_6  = np.square(x1)\n",
    "phy_7  = np.square(x2)\n",
    "phy_8  = np.square(x3)\n",
    "phy_9  = np.square(x4)\n",
    "phy_10 = np.square(x5)\n",
    "\n",
    "# Exponential\n",
    "phy_11 = np.exp(x1)\n",
    "phy_12 = np.exp(x2)\n",
    "phy_13 = np.exp(x3)\n",
    "phy_14 = np.exp(x4)\n",
    "phy_15 = np.exp(x5)\n",
    "\n",
    "# Cosine\n",
    "phy_16 = np.cos(x1)\n",
    "phy_17 = np.cos(x2)\n",
    "phy_18 = np.cos(x3)\n",
    "phy_19 = np.cos(x4)\n",
    "phy_20 = np.cos(x5)\n",
    "\n",
    "# Constant\n",
    "phy_21 = np.ones(phy_20.shape)\n",
    "\n",
    "X_data = (np.vstack((phy_1, phy_2, phy_3, phy_4, phy_5, phy_6, phy_7, phy_8, phy_9, phy_10, phy_11, phy_12, phy_13, phy_14, phy_15, phy_16, phy_17, phy_18, phy_19, phy_20, phy_21))).T\n",
    "\n",
    "df = pd.DataFrame(X_data)\n",
    "df.to_csv(\"xdata.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- LASSO REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "lassocv = LassoCV(cv = 10)\n",
    "lassocv.fit(X_data, y)\n",
    "\n",
    "m_log_alphas = -np.log10(lassocv.alphas_)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(m_log_alphas, lassocv.mse_path_, ':')\n",
    "plt.plot(m_log_alphas, lassocv.mse_path_.mean(axis=-1), 'k',label='Average across the folds', linewidth=2)\n",
    "plt.axvline(-np.log10(lassocv.alpha_), linestyle='--', color='k',label='alpha: CV estimate')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('-log(alpha)')\n",
    "plt.ylabel('Mean square error')\n",
    "plt.title('Mean square error on each fold')\n",
    "plt.axis('tight')\n",
    "plt.ylim(100, 400)\n",
    "\n",
    "df = pd.DataFrame(lassocv.coef_)\n",
    "#df.to_csv(\"lassoWeights.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing regularization path using the Lars lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gregoire/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:17: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LassoLarsCV' object has no attribute 'mse_path_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-51673236ada2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_log_alphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_path_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_log_alphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_path_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Average across the folds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'alpha CV'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LassoLarsCV' object has no attribute 'mse_path_'"
     ]
    }
   ],
   "source": [
    "# ----- LASSO LARS REGRESSION\n",
    "# The object solves the same problem as the LassoCV object. \n",
    "# However, unlike the LassoCV, it find the relevant alphas values by itself. \n",
    "# In general, because of this property, it will be more stable. \n",
    "# However, it is more fragile to heavily multicollinear datasets.\n",
    "\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "import time\n",
    "\n",
    "print(\"Computing regularization path using the Lars lasso...\")\n",
    "t1 = time.time()\n",
    "model = LassoLarsCV(cv=20).fit(X_data, y)\n",
    "\n",
    "t_lasso_lars_cv = time.time() - t1\n",
    "\n",
    "# Display results\n",
    "m_log_alphas = -np.log10(model.cv_alphas_)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(m_log_alphas, model.mse_path_, ':')\n",
    "plt.plot(m_log_alphas, model.mse_path_.mean(axis=-1), 'k', label='Average across the folds', linewidth=2)\n",
    "plt.axvline(-np.log10(model.alpha_), linestyle='--', color='k', label='alpha CV')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('-log(alpha)')\n",
    "plt.ylabel('Mean square error')\n",
    "plt.title('Mean square error on each fold: Lars (train time: %.2fs)' % t_lasso_lars_cv)\n",
    "plt.axis('tight')\n",
    "plt.ylim(0, 200)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(model.coef_)\n",
    "#df.to_csv(\"LassoLarsCV_Weights.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "                    ### OLD APPROACHES ###\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- DO THE BASIC THING GREGOIRE SUGGESTED\n",
    "w_basic = np.dot(np.linalg.pinv(np.dot(X_data.T, X_data) + 10*np.identity(21)), np.dot(X_data.T, y))\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.DataFrame(w_basic)\n",
    "df.to_csv(\"wbasic.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.56892793, 10.56706563, 10.56541115, 10.5639323 , 10.56260097,\n",
       "       10.56139438, 10.56029429, 10.55928607, 10.5583578 , 10.55749967,\n",
       "       10.55670353, 10.5559625 , 10.55527076, 10.55462331, 10.55401582,\n",
       "       10.55344456, 10.55290624, 10.552398  , 10.55191727, 10.55146181,\n",
       "       10.5510296 , 10.55061885, 10.55022795, 10.54985544, 10.54950002,\n",
       "       10.54916049, 10.54883579, 10.54852493, 10.54822703, 10.54794126,\n",
       "       10.54766688, 10.5474032 , 10.54714959, 10.54690548, 10.54667032,\n",
       "       10.54644362, 10.54622493, 10.54601381, 10.54580988, 10.54561277,\n",
       "       10.54542213, 10.54523766, 10.54505905, 10.54488603, 10.54471834,\n",
       "       10.54455573, 10.54439798, 10.54424488, 10.54409622, 10.54395182,\n",
       "       10.5438115 , 10.5436751 , 10.54354245, 10.54341341, 10.54328784,\n",
       "       10.54316561, 10.54304658, 10.54293065, 10.54281771, 10.54270763,\n",
       "       10.54260033, 10.54249571, 10.54239368, 10.54229414, 10.54219703,\n",
       "       10.54210226, 10.54200975, 10.54191944, 10.54183126, 10.54174514,\n",
       "       10.54166102, 10.54157885, 10.54149857, 10.54142011, 10.54134345,\n",
       "       10.54126851, 10.54119526, 10.54112365, 10.54105364, 10.54098519,\n",
       "       10.54091826, 10.5408528 , 10.54078879, 10.54072619, 10.54066496,\n",
       "       10.54060507, 10.54054649, 10.54048919, 10.54043315, 10.54037833,\n",
       "       10.54032471, 10.54027226, 10.54022095, 10.54017077, 10.54012169,\n",
       "       10.54007369, 10.54002674, 10.53998083, 10.53993593, 10.53989203])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- CROSS VALIDATION, FIND BEST LAMBDA\n",
    "\n",
    "# 10-Fold creation (randomly because of 'shuffle')\n",
    "X = X_data\n",
    "\n",
    "Lambda = np.linspace(0.001,10,100)\n",
    "Res = np.zeros(100)\n",
    "kf=KFold(n_splits=10)\n",
    "\n",
    "for j,i in enumerate(Lambda):\n",
    "    RMSE = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        w_hat_closed_form = np.dot(np.linalg.pinv(np.dot(X_train.T, X_train)+Lambda[j]*np.identity(21)), np.dot(X_train.T, y_train))        \n",
    "        y_pred_cf = np.dot(X_test,w_hat_closed_form)        \n",
    "        RMSE += mean_squared_error(y_test, y_pred_cf)**0.5\n",
    "    RMSE = RMSE/np.float64(10)\n",
    "    Res[j]=RMSE\n",
    "Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test/Validation Datapoints', 600, 300]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- SPLIT UP THE DATA INTO TRAINING AND VALIDATION DATA (SIMPLE WAY)\n",
    "\n",
    "# choose random indices from 0 to 899\n",
    "T_index = random.sample(range(0,N_TData-1), 600)\n",
    "V_index  = list(map(int,[x for x in np.linspace(0,899,900) if x not in T_index]));\n",
    "\n",
    "# extract the corresponding data\n",
    "X_train = X_data[T_index,:]\n",
    "X_vali  = X_data[V_index,:]\n",
    "\n",
    "y_train = y[T_index]\n",
    "y_vali  = y[V_index]\n",
    "\n",
    "[\"Test/Validation Datapoints\", len(T_index), len(V_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.910307617250284\n",
      "10.245174457714098\n",
      "11.269241304193839\n",
      "10.436759767051791\n",
      "10.628864011301514\n",
      "9.606820540913057\n",
      "9.956755336302496\n",
      "10.304435578816861\n",
      "10.45776990678672\n",
      "12.744902804574739\n"
     ]
    }
   ],
   "source": [
    "# 10-Fold creation\n",
    "\n",
    "kf=KFold(n_splits=10,shuffle=True)\n",
    "w_tot = np.zeros(21)\n",
    "\n",
    "for train_index, test_index in kf.split(X_data):\n",
    "    X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    w_hat_closed_form = np.dot(np.linalg.pinv(np.dot(X_train.T, X_train)), np.dot(X_train.T, y_train))\n",
    "    w_tot = w_tot + w_hat_closed_form\n",
    "    Y_pred_cf = np.dot(X_test,w_hat_closed_form)\n",
    "    RMSE= mean_squared_error(y_test, Y_pred_cf)**0.5\n",
    "    print(RMSE)\n",
    "    \n",
    "w_res = 1/10*w_tot\n",
    "\n",
    "w_res\n",
    "\n",
    "# save data\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.DataFrame(w_res)\n",
    "df.to_csv(\"w10f.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- TRAINING (OLD)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "# Train the model using the training set\n",
    "regr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.381153182857222\n"
     ]
    }
   ],
   "source": [
    "# ----- VALIDATION (OLD)\n",
    "\n",
    "Y_pred = regr.predict(X_vali)\n",
    "\n",
    "RMSE     = mean_squared_error(y_vali, Y_pred)**0.5\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- EXPORT WEIGHTS\n",
    "\n",
    "Weights = regr.coef_[:]\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.DataFrame(Weights)\n",
    "df.to_csv(\"weights.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.98908243e+00,  3.85070345e+00, -2.05144941e+00,  6.23106878e+00,\n",
       "       -3.22272171e+00, -7.66742691e+00,  2.01682732e+00,  3.04142567e-01,\n",
       "       -1.43369649e+00,  1.30446688e+00,  2.25007339e+00, -4.00958454e+00,\n",
       "       -6.10755118e-03,  6.50836508e-01, -1.98753957e-01, -1.53763236e+01,\n",
       "        3.09603978e+00,  1.31421614e+00, -5.62687517e+00,  3.52626443e+00,\n",
       "        0.00000000e+00])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0740414041404\n"
     ]
    }
   ],
   "source": [
    "# ----- TEST DE LA MORT QUI TUE\n",
    "\n",
    "from   sklearn.model_selection import KFold\n",
    "\n",
    "Lambda = np.linspace(0.01, 0.1, 10000)\n",
    "kf=KFold(n_splits=10)\n",
    "\n",
    "RMSEmin = 1000\n",
    "a_best = 12\n",
    "for j,i in enumerate(Lambda):\n",
    "    clf = Lasso(alpha=i,max_iter=100000)\n",
    "    RMSE = 0\n",
    "    for train_index, test_index in kf.split(X_data):\n",
    "        X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        RMSE += mean_squared_error(y_test, y_pred)**0.5\n",
    "    RMSE = RMSE/np.float64(10)\n",
    "   # print(i)\n",
    "    #print(RMSE)\n",
    "    if RMSE<RMSEmin:\n",
    "        RMSEmin=RMSE\n",
    "        a_best = i\n",
    "print(a_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf = Lasso(alpha=0.0740342034203,max_iter=100000)\n",
    "clf.fit(X_data,y)\n",
    "Weights  = clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.33871983  3.03246988 -2.99083825  6.47790594 -4.25860024 -0.92741643\n",
      "  0.23839544 -0.          1.37731735  0.          0.30538861 -3.46163614\n",
      "  0.19429804 -0.13230313  0.15652668  0.         -0.          0.         -0.\n",
      "  0.          0.        ]\n",
      "[-1.14259556  2.53401831 -2.86702023  7.1776672  -3.60422003 -0.92974649\n",
      "  0.74683888 -0.          1.15078399 -0.          0.34694878 -3.63074716\n",
      "  0.12203304 -0.22128482  0.02991496  0.          0.          0.         -0.\n",
      "  0.          0.        ]\n",
      "[-0.86837319  3.39482775 -2.93405599  6.24503232 -3.91348537 -0.37581763\n",
      "  0.30510177 -0.          1.08414822 -0.         -0.03239589 -3.55810901\n",
      "  0.14097453  0.02304178  0.07723206  0.          0.          0.         -0.\n",
      "  0.          0.        ]\n",
      "[-1.2074292   2.99908163 -2.78655081  6.79946778 -3.08855293 -0.80294797\n",
      "  0.54892593  0.          1.26532266  0.04179561  0.27655729 -3.59967191\n",
      "  0.13051543 -0.1229317  -0.08622112  0.          0.         -0.         -0.\n",
      " -0.          0.        ]\n",
      "[-1.14681508  3.30678496 -2.86103086  6.61949642 -3.74496104 -0.83401737\n",
      "  0.30253544  0.0617197   1.22686063  0.          0.29039097 -3.55992976\n",
      "  0.13932518 -0.11323173  0.06032421  0.          0.         -0.         -0.\n",
      "  0.          0.        ]\n",
      "[-1.24241361  3.26801518 -2.77920129  7.01372508 -4.06579117 -0.73865498\n",
      "  0.39738064 -0.          1.06983688 -0.          0.22660985 -3.59140969\n",
      "  0.17391112 -0.10132608  0.10878441  0.          0.          0.         -0.\n",
      "  0.          0.        ]\n",
      "[-1.23072918  3.43358412 -2.82744402  6.73445101 -4.12945265 -0.64838717\n",
      "  0.25954883 -0.00989939  1.00838214  0.          0.18616798 -3.60124254\n",
      "  0.11850903 -0.0706684   0.10703757  0.         -0.          0.         -0.\n",
      " -0.          0.        ]\n",
      "[-1.65370603  2.8136629  -2.83638034  6.78004392 -4.10103185 -0.61948775\n",
      "  0.550779    0.12658149  1.17448365 -0.          0.24322998 -3.60322446\n",
      "  0.08138253 -0.11175345  0.11947237  0.         -0.         -0.         -0.\n",
      "  0.          0.        ]\n",
      "[-1.00897373  3.21261976 -2.75524992  6.63408588 -3.99076994 -0.71899364\n",
      "  0.4615379  -0.          1.12013609  0.          0.22355525 -3.59459556\n",
      "  0.13756976 -0.09583685  0.1164927   0.          0.          0.         -0.\n",
      " -0.          0.        ]\n",
      "[-1.00150682  3.45270579 -2.69645027  6.93319938 -3.87867884 -0.89513337\n",
      "  0.29985614 -0.          1.2070431   0.          0.28418719 -3.58118729\n",
      "  0.14932502 -0.1151418   0.06363664  0.         -0.          0.         -0.\n",
      "  0.          0.        ]\n",
      "[ -1.18412622e+00   3.14477703e+00  -2.83342220e+00   6.74150749e+00\n",
      "  -3.87755441e+00  -7.49060279e-01   4.11089998e-01   1.78401801e-02\n",
      "   1.16843147e+00   4.17956116e-03   2.35064001e-01  -3.57817535e+00\n",
      "   1.38784366e-01  -1.06143617e-01   7.53200483e-02   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "clf = Lasso(alpha=0.0740414041404,max_iter=100000)\n",
    "Res = np.zeros(21)\n",
    "for train_index, test_index in kf.split(X_data):\n",
    "        X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        Res += clf.coef_\n",
    "        print(clf.coef_)\n",
    "Weights = Res/np.float128(10)\n",
    "print(Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(Weights)\n",
    "df.to_csv(\"output1BGD.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
